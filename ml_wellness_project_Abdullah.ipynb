{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "nA9Y7ga8ng1Z",
        "D0dsR2g1yvSL",
        "g-ATYxFrGrvw",
        "8yEUt7NnHlrM",
        "tEA2Xm5dHt1r",
        "I79__PHVH19G",
        "4_0_7-oCpUZd",
        "hwyV_J3ipUZe",
        "3yB-zSqbpUZe",
        "bn_IUdTipZyH",
        "Nff-vKELpZyI",
        "dJ2tPlVmpsJ0",
        "EyNgTHvd2WFk",
        "-Kee-DAl2viO"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Abdullah-47/ML_Wellness_AI_Assigment/blob/main/ml_wellness_project_Abdullah.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Name**    - Personalized Wellness AI\n",
        "\n"
      ],
      "metadata": {
        "id": "vncDsAP0Gaoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Project Type**    - Regression\n",
        "##### This is my custom ML template"
      ],
      "metadata": {
        "id": "beRrZCGUAJYm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Summary -**"
      ],
      "metadata": {
        "id": "FJNUwmbgGyua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This project developed a proof-of-concept for a Personalized Wellness AI using synthetic data. We explored relationships between wellness metrics like sleep, steps, stress, mood, and productivity through EDA and hypothesis testing. Predictive models (Linear Regression and Random Forest) were built and evaluated to predict productivity score, with Linear Regression performing slightly better on this synthetic dataset. Key challenges and future directions, including the use of real-world data and ethical considerations, were discussed."
      ],
      "metadata": {
        "id": "F6v_1wHtG2nS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GitHub Link -**"
      ],
      "metadata": {
        "id": "w6K7xa23Elo4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://github.com/Abdullah-47/ML_Wellness_AI_Assigment"
      ],
      "metadata": {
        "id": "h1o69JH3Eqqn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem Statement**\n"
      ],
      "metadata": {
        "id": "yQaldy8SH6Dl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The increasing awareness of personal well-being highlights the need for tailored guidance to improve daily habits and overall health outcomes.\n",
        "\n",
        "Existing general wellness advice often lacks personalization, making it less effective for individuals with unique needs and patterns.\n",
        "\n",
        "This project aims to address the challenge of providing personalized wellness recommendations by developing an AI model that can predict key wellness indicators, such as productivity, based on individual behavioral and health data, thereby enabling more targeted and effective interventions."
      ],
      "metadata": {
        "id": "DpeJGUA3kjGy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Let's Begin !***"
      ],
      "metadata": {
        "id": "O_i_v8NEhb9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***Phase 1: Technical Proof-of-Concept***"
      ],
      "metadata": {
        "id": "HhfV-JJviCcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "Y3lxredqlCYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "import pandas as pd #For data manipulation\n",
        "import numpy as np #For mathematical operations\n",
        "import matplotlib.pyplot as plt #For visualization\n",
        "import seaborn as sns #For heatmaps\n",
        "from scipy.stats import skewnorm, gamma #For synthetic data generation\n",
        "from sklearn.linear_model import LinearRegression #Linear Regression Model\n",
        "\n",
        "\n",
        "import warnings #Ignore pylance warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "M8Vqi-pPk-HR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Synthetic Data generation"
      ],
      "metadata": {
        "id": "3RnN4peoiCZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Dataset\n",
        "\n",
        "# Configuration\n",
        "np.random.seed(42)\n",
        "n_samples = 1000  # Number of synthetic users\n",
        "\n",
        "# Generate core features with realistic distributions\n",
        "data = {\n",
        "    # Physical activity (skewed right: most people walk 5k-10k steps)\n",
        "    'daily_steps': skewnorm.rvs(5, loc=7000, scale=3000, size=n_samples).astype(int),\n",
        "\n",
        "    # Sleep duration (normal distribution with some short sleepers)\n",
        "    'sleep_duration_hours': np.clip(np.random.normal(7.2, 1.2, n_samples), 4, 10),\n",
        "\n",
        "    # Stress level (gamma distribution: most have moderate stress)\n",
        "    'stress_level': np.round(np.clip(gamma.rvs(2, loc=1, scale=1.5, size=n_samples), 1, 10), 1),\n",
        "\n",
        "    # Age (bimodal distribution: working adults and seniors)\n",
        "    'age': np.concatenate([\n",
        "        np.random.normal(35, 5, int(n_samples*0.6)),\n",
        "        np.random.normal(65, 8, int(n_samples*0.4))\n",
        "    ]),\n",
        "\n",
        "    # Water intake (uniform with some outliers)\n",
        "    'water_intake_liters': np.clip(np.random.normal(2.5, 0.8, n_samples), 0.5, 5)\n",
        "}\n",
        "\n",
        "# Create derived features with relationships\n",
        "data['mood_score'] = np.clip(\n",
        "    3.5 +\n",
        "    0.00004 * data['daily_steps'] +\n",
        "    0.35 * data['sleep_duration_hours'] -\n",
        "    0.25 * data['stress_level'] +\n",
        "    np.random.normal(0, 1.2, n_samples),\n",
        "    1, 10\n",
        ").round(1)\n",
        "\n",
        "data['productivity_score'] = np.clip(\n",
        "    5 +\n",
        "    0.00003 * data['daily_steps'] +\n",
        "    0.2 * data['sleep_duration_hours'] -\n",
        "    0.15 * data['stress_level'] +\n",
        "    0.1 * data['mood_score'] +\n",
        "    np.random.normal(0, 1, n_samples),\n",
        "    1, 10\n",
        ").round(1)\n",
        "\n",
        "# Dietary categories (categorical with probabilities)\n",
        "diet_categories = ['balanced', 'high_carb', 'high_protein', 'low_fat', 'vegetarian']\n",
        "data['dietary_category'] = np.random.choice(\n",
        "    diet_categories,\n",
        "    size=n_samples,\n",
        "    p=[0.4, 0.15, 0.2, 0.15, 0.1]\n",
        ")\n",
        "\n",
        "# Create DataFrame\n",
        "wellness_df = pd.DataFrame(data)\n",
        "\n",
        "# Add date sequence (last 30 days)\n",
        "date_range = pd.date_range(end=pd.Timestamp.today(), periods=30, freq='D')\n",
        "wellness_df['date'] = np.random.choice(date_range, size=n_samples)\n",
        "\n",
        "# Add user IDs\n",
        "wellness_df['user_id'] = ['user_' + str(i).zfill(4) for i in range(n_samples)]\n",
        "\n",
        "# Reorder columns\n",
        "wellness_df = wellness_df[['user_id', 'date', 'age', 'daily_steps', 'sleep_duration_hours',\n",
        "                          'water_intake_liters', 'stress_level', 'mood_score',\n",
        "                          'productivity_score', 'dietary_category']]\n"
      ],
      "metadata": {
        "id": "4CkvbW_SlZ_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset First View"
      ],
      "metadata": {
        "id": "x71ZqKXriCWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset First Look\n",
        "# Preview\n",
        "print(wellness_df.head())\n",
        "\n",
        "# Save to CSV\n",
        "wellness_df.to_csv('synthetic_wellness_data.csv', index=False)\n"
      ],
      "metadata": {
        "id": "LWNFOSvLl09H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Rows & Columns count"
      ],
      "metadata": {
        "id": "7hBIi_osiCS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Rows & Columns count\n",
        "wellness_df.shape"
      ],
      "metadata": {
        "id": "Kllu7SJgmLij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Information"
      ],
      "metadata": {
        "id": "JlHwYmJAmNHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Info\n",
        "wellness_df.info()"
      ],
      "metadata": {
        "id": "e9hRXRi6meOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Duplicate Values"
      ],
      "metadata": {
        "id": "35m5QtbWiB9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Duplicate Value Count\n",
        "wellness_df.duplicated().sum()"
      ],
      "metadata": {
        "id": "1sLdpKYkmox0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Missing Values/Null Values"
      ],
      "metadata": {
        "id": "PoPl-ycgm1ru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing Values/Null Values Count\n",
        "wellness_df.isnull().sum()"
      ],
      "metadata": {
        "id": "GgHWkxvamxVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the missing values\n",
        "# No missing values"
      ],
      "metadata": {
        "id": "3q5wnI3om9sJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Columns\n",
        "wellness_df.columns"
      ],
      "metadata": {
        "id": "j7xfkqrt5Ag5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Describe\n",
        "wellness_df.describe()"
      ],
      "metadata": {
        "id": "DnOaZdaE5Q5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Understanding Variables***"
      ],
      "metadata": {
        "id": "nA9Y7ga8ng1Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check Unique Values for each variable."
      ],
      "metadata": {
        "id": "u3PMJOP6ngxN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Unique Values for each variable.\n",
        "for column in wellness_df.columns:\n",
        "    unique_values = wellness_df[column].unique()\n",
        "    print(f\"Unique values for {column}: {unique_values}\")"
      ],
      "metadata": {
        "id": "zms12Yq5n-jE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Data Vizualization, Storytelling & Experimenting with charts : Understand the relationships between variables***"
      ],
      "metadata": {
        "id": "GF8Ens_Soomf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 1"
      ],
      "metadata": {
        "id": "0wOQAZs5pc--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Univariate Analysis: Histograms for numerical features\n",
        "numerical_features = ['age', 'daily_steps', 'sleep_duration_hours', 'water_intake_liters', 'stress_level', 'mood_score', 'productivity_score']\n",
        "plt.figure(figsize=(15, 10))\n",
        "for i, col in enumerate(numerical_features):\n",
        "    plt.subplot(3, 3, i + 1)\n",
        "    sns.histplot(wellness_df[col], kde=True)\n",
        "    plt.title(f'Distribution of {col}')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7v_ESjsspbW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did i pick the specific chart?"
      ],
      "metadata": {
        "id": "K5QZ13OEpz2H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Histograms** are fundamental for understanding the distribution of a single numerical variable. They show the frequency of data points within different bins, allowing us to see the shape of the distribution (e.g., normal, skewed), identify modes, and detect potential outliers. Plotting multiple histograms provides a quick overview of the distributions of all numerical features."
      ],
      "metadata": {
        "id": "XESiWehPqBRc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "lQ7QKXXCp7Bj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the histograms, you can see the distribution of each numerical variable. For example, you can observe the typical range of daily steps, whether sleep duration is normally distributed, if stress levels are skewed, and the distribution of mood and productivity scores. This gives you a sense of the typical values and variability within each feature."
      ],
      "metadata": {
        "id": "C_j1G7yiqdRP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "448CDAPjqfQr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Understanding the distribution of wellness metrics (like mood and productivity) helps in setting realistic goals and benchmarks for users. Knowing the distribution of factors influencing wellness (like steps, sleep, stress) helps in tailoring personalized recommendations. For instance, if stress levels are highly skewed towards the higher end, the AI could focus more on stress management techniques. There are no direct negative growth insights, but unusual or multimodal distributions might indicate distinct user segments that require different approaches, and failing to recognize these could limit the AI's effectiveness for certain groups."
      ],
      "metadata": {
        "id": "3cspy4FjqxJW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 2"
      ],
      "metadata": {
        "id": "KSlN3yHqYklG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Univariate Analysis: Count plot for the categorical feature\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.countplot(data=wellness_df, x='dietary_category')\n",
        "plt.title('Distribution of Dietary Categories')\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "R4YgtaqtYklH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did i pick the specific chart?"
      ],
      "metadata": {
        "id": "t6dVpIINYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A **count plot** is ideal for visualizing the distribution of a single categorical variable. It clearly shows the frequency or number of occurrences for each category, making it easy to understand the proportion of users in each dietary group."
      ],
      "metadata": {
        "id": "5aaW0BYyYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "ijmpgYnKYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The count plot shows the distribution of users across different dietary categories. The most frequent category is 'balanced', followed by 'high_protein' and 'low_fat'. 'High_carb' and 'vegetarian' diets are less common in this synthetic dataset."
      ],
      "metadata": {
        "id": "PSx9atu2YklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "-JiQyfWJYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Understanding the distribution of dietary categories is crucial for a personalized wellness AI. Knowing which diets are most common allows for tailoring recommendations and content. For example, if 'balanced' and 'high_protein' are prevalent, the AI can prioritize features and recommendations relevant to these diets. There are no direct insights leading to negative growth from this chart, but a very skewed distribution towards unhealthy diets could indicate a target area for intervention and content focusing on healthier eating."
      ],
      "metadata": {
        "id": "BcBbebzrYklV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 3"
      ],
      "metadata": {
        "id": "EM7whBJCYoAo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Bivariate Analysis: Scatter plot (Example: Sleep Duration vs Mood Score)\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.scatterplot(data=wellness_df, x='sleep_duration_hours', y='mood_score')\n",
        "plt.title('Sleep Duration vs Mood Score')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "t6GMdE67YoAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did i pick the specific chart?"
      ],
      "metadata": {
        "id": "fge-S5ZAYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A **scatter plot** is used to visualize the relationship between two numerical variables. By plotting sleep duration against mood score, we can visually inspect if there is a pattern, trend, or correlation between these two variables."
      ],
      "metadata": {
        "id": "5dBItgRVYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "85gYPyotYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The scatter plot shows a general trend where higher sleep duration appears to be associated with higher mood scores, although there is significant scatter. This visually supports the idea of a positive relationship between sleep and mood."
      ],
      "metadata": {
        "id": "4jstXR6OYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "RoGjAbkUYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This insight can lead to positive business impact by informing the AI's recommendations. If better sleep leads to improved mood, the AI can prioritize sleep-related recommendations (e.g., sleep hygiene tips, consistent sleep schedules). This could improve user well-being and engagement with the platform. There are no direct negative growth insights, but if the plot showed no relationship, it would indicate that sleep duration alone might not be a strong predictor of mood in this dataset, requiring the AI to consider other factors."
      ],
      "metadata": {
        "id": "zfJ8IqMcYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 4"
      ],
      "metadata": {
        "id": "YJ55k-q6phqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Bivariate Analysis: Box plot (Example: Dietary Category vs Mood Score)\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.boxplot(data=wellness_df, x='dietary_category', y='mood_score')\n",
        "plt.title('Mood Score by Dietary Category')\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "B2aS4O1ophqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did i pick the specific chart?"
      ],
      "metadata": {
        "id": "gCFgpxoyphqP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A **box plot** is effective for visualizing the distribution of a numerical variable across different categories of a categorical variable. It allows for easy comparison of the median, quartiles, and potential outliers of mood scores for each dietary category."
      ],
      "metadata": {
        "id": "TVxDimi2phqP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "OVtJsKN_phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The box plot shows the range and distribution of mood scores within each dietary category. You can observe differences in the median mood score and the spread of scores across the different diets. For example, one dietary category might show a higher median mood score or less variability compared to others."
      ],
      "metadata": {
        "id": "ngGi97qjphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "lssrdh5qphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Understanding how dietary categories relate to mood can inform personalized dietary recommendations. If certain diets are associated with higher mood scores, the AI can suggest or encourage those dietary approaches for users aiming to improve their mood. This can enhance the AI's effectiveness and user satisfaction. If a particular diet showed significantly lower mood scores, it could indicate a need for the AI to provide targeted support or alternative suggestions for users following that diet, potentially mitigating negative user experiences."
      ],
      "metadata": {
        "id": "tBpY5ekJphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 5 - Correlation Heatmap"
      ],
      "metadata": {
        "id": "NC_X3p0fY2L0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Correlation Heatmap visualization code\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.heatmap(wellness_df.corr(numeric_only=True), annot=True, cmap='coolwarm', fmt=\".2f\")\n",
        "plt.title('Correlation Heatmap of Wellness Data')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xyC9zolEZNRQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did i pick the specific chart?"
      ],
      "metadata": {
        "id": "UV0SzAkaZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A **correlation heatmap** is a powerful tool for visualizing the pairwise correlation coefficients between multiple numerical variables simultaneously. It uses color intensity to represent the strength and direction of the correlation, making it easy to quickly identify strong positive or negative relationships."
      ],
      "metadata": {
        "id": "DVPuT8LYZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "YPEH6qLeZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The heatmap reveals the linear relationships between all pairs of numerical features. You can see which variables are strongly positively correlated (e.g., higher sleep duration and higher mood score) and which are strongly negatively correlated (e.g., higher stress level and lower productivity score). It also shows variables with weak or no linear correlation."
      ],
      "metadata": {
        "id": "bfSqtnDqZNRR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. Will the gained insights help creating a positive business impact? Are there any insights that lead to negative growth? Justify with specific reason.**"
      ],
      "metadata": {
        "id": "8U4ktbiCyMkS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Understanding the correlations between variables is fundamental for building predictive models and providing personalized recommendations. Strong positive or negative correlations indicate variables that are likely important predictors of wellness outcomes. This helps in feature selection for machine learning models, leading to more accurate predictions and relevant recommendations. There are no direct negative growth insights from the heatmap itself, but weak correlations between seemingly related variables might indicate limitations in the data or the need to consider non-linear relationships, potentially impacting the effectiveness of simple linear models."
      ],
      "metadata": {
        "id": "TQAPDPMayO3a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 6 - Pair Plot"
      ],
      "metadata": {
        "id": "q29F0dvdveiT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pair Plot visualization code\n",
        "sns.pairplot(wellness_df[['daily_steps', 'sleep_duration_hours', 'stress_level', 'mood_score', 'productivity_score', 'water_intake_liters']])\n",
        "plt.suptitle('Pair Plot of Wellness Data', y=1.02)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "o58-TEIhveiU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did i pick the specific chart?"
      ],
      "metadata": {
        "id": "EXh0U9oCveiU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A **pair plot** is a comprehensive visualization that creates a grid of scatter plots for every pair of numerical variables in a dataset, and histograms (or kernel density estimates) on the diagonal to show the univariate distributions. It provides a quick overview of the relationships and distributions of multiple variables in one figure."
      ],
      "metadata": {
        "id": "eMmPjTByveiU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "22aHeOlLveiV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The pair plot allows for a detailed visual inspection of the relationships between pairs of numerical variables. You can observe the shape of the relationships (linear, non-linear), the spread of the data points, and identify potential outliers. The diagonal histograms show the individual distributions of each variable, complementing the bivariate scatter plots."
      ],
      "metadata": {
        "id": "uPQ8RGwHveiV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. Will the gained insights help creating a positive business impact? Justify with specific reason.**"
      ],
      "metadata": {
        "id": "dYFd3-46yVVC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "The insights from the pair plot, similar to the heatmap, are valuable for understanding variable relationships and informing feature engineering and model building. Visualizing the relationships can help identify potential issues like heteroscedasticity or non-linear patterns that might require data transformations or different modeling techniques. This leads to more robust and accurate models, improving the AI's ability to provide effective personalized recommendations. If the pair plots reveal unexpected or weak relationships, it might indicate limitations in the dataset or the need for collecting more relevant data, which could indirectly impact the potential for positive business growth if not addressed."
      ],
      "metadata": {
        "id": "1ieH2WsuyVNa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q1: Synthetic Data Design & Insights"
      ],
      "metadata": {
        "id": "D0dsR2g1yvSL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**Synthetic Data Generation Strategy:**\n",
        "\n",
        "The synthetic data was generated using Python's `numpy` and `scipy.stats` libraries to create realistic distributions for various wellness metrics. The core idea was to simulate data for 1000 users over a 30-day period, incorporating both independent features with specific distributions (like skewed, normal, or gamma) and derived features with defined relationships to mimic real-world wellness interactions.\n",
        "\n",
        "**Specific Features and Why They Are Crucial for Wellness Recommendations:**\n",
        "\n",
        "The dataset includes the following features:\n",
        "\n",
        "-   **`user_id`**: A unique identifier for each synthetic user, essential for tracking individual progress and providing personalized recommendations.\n",
        "-   **`date`**: The date of the wellness entry, crucial for time-series analysis and understanding trends over time.\n",
        "-   **`age`**: Age is a significant demographic factor that can influence wellness patterns and the type of recommendations that are relevant.\n",
        "-   **`daily_steps`**: A key indicator of physical activity, fundamental for recommendations related to fitness and energy levels.\n",
        "-   **`sleep_duration_hours`**: Sleep is vital for physical and mental well-being, directly impacting mood and productivity.\n",
        "-   **`water_intake_liters`**: Hydration affects various bodily functions and can influence energy levels and overall health.\n",
        "-   **`stress_level`**: Stress is a major factor impacting both mental and physical health, and understanding it is key for providing stress management recommendations.\n",
        "-   **`mood_score`**: A subjective measure of emotional well-being, a primary outcome the AI aims to improve.\n",
        "-   **`productivity_score`**: An indicator of how effectively a user is able to perform tasks, another key outcome influenced by other wellness factors.\n",
        "-   **`dietary_category`**: Represents different eating habits, important for tailoring nutritional recommendations.\n",
        "\n",
        "These features were chosen because they represent common, interconnected aspects of daily wellness that a personalized AI would typically track and use to provide holistic recommendations.\n",
        "\n",
        "**Creating Realistic Relationships and Variability:**\n",
        "\n",
        "-   **Distributions:** Different statistical distributions (skewnorm, normal, gamma, uniform) were used for various features to mimic the natural variability and typical patterns seen in real-world data (e.g., steps are often right-skewed, sleep duration is often close to a normal distribution).\n",
        "-   **Derived Features:** `mood_score` and `productivity_score` were created as derived features, calculated based on linear combinations of other features (`daily_steps`, `sleep_duration_hours`, `stress_level`) plus some random noise. This introduces realistic relationships where changes in inputs (like sleep or stress) influence outcomes (like mood and productivity).\n",
        "-   **Clamping and Rounding:** Values were clamped within reasonable ranges (e.g., sleep duration between 4 and 10 hours, scores between 1 and 10) and rounded where appropriate to make the data appear more realistic.\n",
        "-   **Categorical Data:** Dietary categories were assigned with specific probabilities to reflect that some diets are more common than others.\n",
        "-   **Date and User IDs:** Unique user IDs and a date sequence were added to simulate longitudinal data for multiple individuals.\n",
        "\n",
        "**Key Assumptions Made:**\n",
        "\n",
        "-   **Linear Relationships in Derived Features:** The formulas for `mood_score` and `productivity_score` assume a mostly linear relationship with the influencing factors (steps, sleep, stress), with some added random noise. Real-world relationships might be more complex or non-linear.\n",
        "-   **Distribution Shapes:** The chosen statistical distributions are assumptions about the underlying patterns of these wellness metrics in a population.\n",
        "-   **Categorical Proportions:** The probabilities assigned to dietary categories are assumptions about their prevalence.\n",
        "-   **Independence (mostly):** While derived features have relationships, the base features (steps, sleep, stress, age, water intake) are generated largely independently, which might not fully capture all complex interdependencies in reality.\n",
        "\n",
        "**Patterns and \"Story\" Revealed by the 6 Visuals:**\n",
        "\n",
        "The six visuals collectively tell a story about the synthetic users' wellness patterns and the factors that influence them:\n",
        "\n",
        "1.  **Histograms (Univariate Numerical):** Show the individual distributions. We see that daily steps are somewhat right-skewed (more people with moderate steps), sleep duration is roughly normal, stress levels are skewed towards lower to moderate levels, and mood/productivity scores are distributed across the 1-10 scale, likely reflecting the combined influence of other factors.\n",
        "2.  **Count Plot (Univariate Categorical):** Reveals that a 'balanced' diet is the most common among synthetic users, providing context for dietary recommendations.\n",
        "3.  **Scatter Plot (Sleep vs Mood):** Visually suggests a positive trend -- more sleep generally correlates with higher mood scores, supporting the initial hypothesis.\n",
        "4.  **Box Plot (Dietary Category vs Mood):** Allows for comparing mood score distributions across different diets. You can see if certain diets tend to have higher or lower median mood scores and how variable mood is within each dietary group.\n",
        "5.  **Correlation Heatmap:** Provides a concise summary of all pairwise linear relationships between numerical features. It confirms the positive correlation between sleep and mood, the negative correlation between stress and productivity, and also shows other relationships like the moderate positive correlation between mood and productivity.\n",
        "6.  **Pair Plot:** Offers a more detailed look at the bivariate relationships and univariate distributions. It visually reinforces the trends seen in the scatter plot and heatmap and helps identify if relationships are linear or if there are unusual clusters or outliers. The diagonal confirms the distributions seen in the histograms.\n",
        "\n",
        "In summary, the visualizations reveal that in this synthetic dataset, sleep and stress are notable factors influencing mood and productivity, and the dataset contains a diverse range of user behaviors and wellness states across different metrics and dietary categories."
      ],
      "metadata": {
        "id": "bpzmtW3hy2Kj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Hypothesis Testing***"
      ],
      "metadata": {
        "id": "g-ATYxFrGrvw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 1: There is a positive relationship between sleep duration and mood score.\n",
        "\n",
        "### Hypothetical Statement - 2: Higher stress levels are associated with lower productivity scores.\n",
        "\n",
        "### Hypothetical Statement - 3: Individuals with higher daily steps tend to have higher mood and productivity scores.\n"
      ],
      "metadata": {
        "id": "-7MS06SUHkB-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 1: There is a positive relationship between sleep duration and mood score."
      ],
      "metadata": {
        "id": "8yEUt7NnHlrM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "tEA2Xm5dHt1r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Null Hypothesis (H₀):** There is no significant relationship between sleep duration and mood score. (e.g., The correlation coefficient between sleep duration and mood score is zero).\n",
        "\n",
        "**Alternate Hypothesis (H₁):** There is a positive relationship between sleep duration and mood score. (e.g., The correlation coefficient between sleep duration and mood score is greater than zero)."
      ],
      "metadata": {
        "id": "HI9ZP0laH0D-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "I79__PHVH19G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import pearsonr\n",
        "\n",
        "# Hypothesis 1: Positive relationship between sleep duration and mood score.\n",
        "# Null Hypothesis (H₀): There is no significant positive relationship (correlation <= 0).\n",
        "# Alternate Hypothesis (H₁): There is a significant positive relationship (correlation > 0).\n",
        "\n",
        "# Perform Pearson correlation test\n",
        "corr_sleep_mood, p_value_sleep_mood = pearsonr(wellness_df['sleep_duration_hours'], wellness_df['mood_score'])\n",
        "\n",
        "print(f\"Hypothesis 1:\")\n",
        "print(f\"Pearson Correlation Coefficient (Sleep Duration vs Mood Score): {corr_sleep_mood:.4f}\")\n",
        "print(f\"P-value: {p_value_sleep_mood:.4f}\")\n",
        "\n",
        "# Interpret the result for a one-tailed test (positive relationship)\n",
        "alpha = 0.05\n",
        "if p_value_sleep_mood / 2 < alpha and corr_sleep_mood > 0:\n",
        "    print(\"Conclusion: Reject the null hypothesis. There is a significant positive relationship between sleep duration and mood score.\")\n",
        "else:\n",
        "    print(\"Conclusion: Fail to reject the null hypothesis. There is no significant positive relationship between sleep duration and mood score.\")"
      ],
      "metadata": {
        "id": "oZrfquKtyian"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 2: Higher stress levels are associated with lower productivity scores.\n"
      ],
      "metadata": {
        "id": "4_0_7-oCpUZd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "hwyV_J3ipUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Null Hypothesis (H₀):** There is no significant relationship between stress level and productivity score. (e.g., The correlation coefficient between stress level and productivity score is zero).\n",
        "\n",
        "**Alternate Hypothesis (H₁):** There is a negative relationship between stress level and productivity score. (e.g., The correlation coefficient between stress level and productivity score is less than zero)."
      ],
      "metadata": {
        "id": "FnpLGJ-4pUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "3yB-zSqbpUZe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import pearsonr\n",
        "\n",
        "# Hypothesis 2: Higher stress levels are associated with lower productivity scores.\n",
        "# Null Hypothesis (H₀): There is no significant negative relationship (correlation >= 0).\n",
        "# Alternate Hypothesis (H₁): There is a significant negative relationship (correlation < 0).\n",
        "\n",
        "# Perform Pearson correlation test\n",
        "corr_stress_productivity, p_value_stress_productivity = pearsonr(wellness_df['stress_level'], wellness_df['productivity_score'])\n",
        "\n",
        "print(f\"\\nHypothesis 2:\")\n",
        "print(f\"Pearson Correlation Coefficient (Stress Level vs Productivity Score): {corr_stress_productivity:.4f}\")\n",
        "print(f\"P-value: {p_value_stress_productivity:.4f}\")\n",
        "\n",
        "# Interpret the result for a one-tailed test (negative relationship)\n",
        "alpha = 0.05\n",
        "if p_value_stress_productivity / 2 < alpha and corr_stress_productivity < 0:\n",
        "    print(\"Conclusion: Reject the null hypothesis. There is a significant negative relationship between stress level and productivity score.\")\n",
        "else:\n",
        "    print(\"Conclusion: Fail to reject the null hypothesis. There is no significant negative relationship between stress level and productivity score.\")"
      ],
      "metadata": {
        "id": "sWxdNTXNpUZe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 3: Individuals with higher daily steps tend to have higher mood and productivity scores.\n"
      ],
      "metadata": {
        "id": "bn_IUdTipZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "49K5P_iCpZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Null Hypothesis (H₀):** There is no significant positive relationship between daily steps and mood score, nor between daily steps and productivity score. (e.g., The correlation coefficients are zero or not positive).\n",
        "\n",
        "**Alternate Hypothesis (H₁):** There is a positive relationship between daily steps and mood score, and/or between daily steps and productivity score. (e.g., At least one of the correlation coefficients is greater than zero)."
      ],
      "metadata": {
        "id": "7gWI5rT9pZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "Nff-vKELpZyI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import pearsonr\n",
        "\n",
        "# Hypothesis 3: Individuals with higher daily steps tend to have higher mood and productivity scores.\n",
        "# This is a slightly more complex hypothesis involving two potential positive relationships.\n",
        "# We'll test each relationship separately.\n",
        "\n",
        "# Hypothesis 3a: Daily steps and mood score\n",
        "# Null Hypothesis (H₀): No significant positive relationship (correlation <= 0).\n",
        "# Alternate Hypothesis (H₁): Significant positive relationship (correlation > 0).\n",
        "corr_steps_mood, p_value_steps_mood = pearsonr(wellness_df['daily_steps'], wellness_df['mood_score'])\n",
        "\n",
        "print(f\"\\nHypothesis 3a (Daily Steps vs Mood Score):\")\n",
        "print(f\"Pearson Correlation Coefficient: {corr_steps_mood:.4f}\")\n",
        "print(f\"P-value: {p_value_steps_mood:.4f}\")\n",
        "\n",
        "# Interpret for one-tailed test (positive relationship)\n",
        "alpha = 0.05\n",
        "if p_value_steps_mood / 2 < alpha and corr_steps_mood > 0:\n",
        "    print(\"Conclusion: Reject the null hypothesis. There is a significant positive relationship between daily steps and mood score.\")\n",
        "else:\n",
        "    print(\"Conclusion: Fail to reject the null hypothesis. There is no significant positive relationship between daily steps and mood score.\")\n",
        "\n",
        "# Hypothesis 3b: Daily steps and productivity score\n",
        "# Null Hypothesis (H₀): No significant positive relationship (correlation <= 0).\n",
        "# Alternate Hypothesis (H₁): Significant positive relationship (correlation > 0).\n",
        "corr_steps_productivity, p_value_steps_productivity = pearsonr(wellness_df['daily_steps'], wellness_df['productivity_score'])\n",
        "\n",
        "print(f\"\\nHypothesis 3b (Daily Steps vs Productivity Score):\")\n",
        "print(f\"Pearson Correlation Coefficient: {corr_steps_productivity:.4f}\")\n",
        "print(f\"P-value: {p_value_steps_productivity:.4f}\")\n",
        "\n",
        "# Interpret for one-tailed test (positive relationship)\n",
        "if p_value_steps_productivity / 2 < alpha and corr_steps_productivity > 0:\n",
        "    print(\"Conclusion: Reject the null hypothesis. There is a significant positive relationship between daily steps and productivity score.\")\n",
        "else:\n",
        "    print(\"Conclusion: Fail to reject the null hypothesis. There is no significant positive relationship between daily steps and productivity score.\")\n",
        "\n",
        "# Overall conclusion for Hypothesis 3\n",
        "print(\"\\nOverall Conclusion for Hypothesis 3:\")\n",
        "if (p_value_steps_mood / 2 < alpha and corr_steps_mood > 0) or (p_value_steps_productivity / 2 < alpha and corr_steps_productivity > 0):\n",
        "    print(\"Conclusion: At least one of the relationships (daily steps vs mood or daily steps vs productivity) is significantly positive. Reject the overall null hypothesis.\")\n",
        "else:\n",
        "     print(\"Conclusion: Neither relationship (daily steps vs mood nor daily steps vs productivity) is significantly positive. Fail to reject the overall null hypothesis.\")"
      ],
      "metadata": {
        "id": "s6AnJQjtpZyI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Feature Engineering & Data Pre-processing***"
      ],
      "metadata": {
        "id": "yLjJCtPM0KBk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Categorical Encoding"
      ],
      "metadata": {
        "id": "89xtkJwZ18nB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode your categorical columns\n",
        "# Perform one-hot encoding on 'dietary_category'\n",
        "dietary_encoded = pd.get_dummies(wellness_df['dietary_category'], prefix='diet')\n",
        "\n",
        "# Concatenate the encoded features with the original dataframe and drop the original column\n",
        "wellness_df = pd.concat([wellness_df.drop('dietary_category', axis=1), dietary_encoded], axis=1)\n",
        "\n",
        "# Display the first few rows of the updated dataframe\n",
        "display(wellness_df.head())"
      ],
      "metadata": {
        "id": "21JmIYMG2hEo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What all categorical encoding techniques have you used & why did you use those techniques?"
      ],
      "metadata": {
        "id": "67NQN5KX2AMe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "UDaue5h32n_G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Feature Manipulation & Selection"
      ],
      "metadata": {
        "id": "-oLEiFgy-5Pf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Data Transformation"
      ],
      "metadata": {
        "id": "TNVZ9zx19K6k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Do you think that your data needs to be transformed? If yes, which transformation have you used. Explain Why?"
      ],
      "metadata": {
        "id": "nqoHp30x9hH9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Transform Your data\n",
        "# Engineer 'day_of_week' feature from the 'date' column\n",
        "wellness_df['day_of_week'] = wellness_df['date'].dt.dayofweek\n",
        "\n",
        "# Display the first few rows with the new feature\n",
        "display(wellness_df.head())"
      ],
      "metadata": {
        "id": "I6quWQ1T9rtH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8. Data Splitting"
      ],
      "metadata": {
        "id": "BhH2vgX9EjGr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split your data to train and test. Choose Splitting ratio wisely.\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Define features (X) and target (y)\n",
        "# Exclude 'user_id' and 'date'\n",
        "features = wellness_df.drop(['user_id', 'date', 'productivity_score'], axis=1)\n",
        "target = wellness_df['productivity_score']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
        "\n",
        "print(\"Training features shape:\", X_train.shape)\n",
        "print(\"Testing features shape:\", X_test.shape)\n",
        "print(\"Training target shape:\", y_train.shape)\n",
        "print(\"Testing target shape:\", y_test.shape)"
      ],
      "metadata": {
        "id": "0CTyd2UwEyNM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What data splitting ratio have you used and why?"
      ],
      "metadata": {
        "id": "qjKvONjwE8ra"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Traditional 80/20 split"
      ],
      "metadata": {
        "id": "Y2lJ8cobFDb_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q2: Model Selection & Justification"
      ],
      "metadata": {
        "id": "HD3yTO7VDV0P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the context of predicting `productivity_score`:\n",
        "\n",
        "**Linear Regression:** Useful for initial insights and understanding the main linear drivers of productivity. If the data is simple and the relationships are mostly linear, it might be sufficient and offers the benefit of easy interpretability for explaining recommendations.\n",
        "\n",
        "**Random Forest Regressor:** More likely to capture the nuances and complex interactions in real-world wellness data, potentially leading to more accurate predictions and thus more effective personalized recommendations, even if the direct interpretability is lower. The feature importance can still help in understanding which factors are generally most important.\n",
        "\n",
        "**Future Recommendation:** If i had more time i would have found a `real-world` dataset which would carry much more impact that a synthetic dataset and perform extensive data pre-processing and try to find relationships within variables and build much more reliable and useful model."
      ],
      "metadata": {
        "id": "i8O4qVLrDjSf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***ML Model Implementation***"
      ],
      "metadata": {
        "id": "VfCC591jGiD4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 1"
      ],
      "metadata": {
        "id": "OB4l2ZhMeS1U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation\n",
        "\n",
        "# Instantiate the Linear Regression model\n",
        "model = LinearRegression()\n",
        "\n",
        "# Fit the Algorithm\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the model\n",
        "y_pred = model.predict(X_test)\n"
      ],
      "metadata": {
        "id": "7ebyywQieS1U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "ArJBuiUVfxKd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate Mean Squared Error\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "\n",
        "# Calculate R-squared score\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "# Print the evaluation metrics\n",
        "print(f\"Mean Squared Error (MSE): {mse:.4f}\")\n",
        "print(f\"R-squared (R2) Score: {r2:.4f}\")\n",
        "\n",
        "#MSE and r2 visualization\n"
      ],
      "metadata": {
        "id": "rqD5ZohzfxKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation"
      ],
      "metadata": {
        "id": "4qY1EAkEfxKe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "from sklearn.model_selection import KFold, cross_val_score\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Re-instantiate the Linear Regression model\n",
        "model_cv = LinearRegression()\n",
        "\n",
        "# Define the number of splits for K-Fold cross-validation\n",
        "n_splits = 5  # You can adjust this number\n",
        "\n",
        "# Instantiate KFold\n",
        "kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
        "\n",
        "# Perform cross-validation using MSE and R-squared as scoring metrics\n",
        "cv_mse_scores = -cross_val_score(model_cv, X_train, y_train, cv=kf, scoring='neg_mean_squared_error')\n",
        "cv_r2_scores = cross_val_score(model_cv, X_train, y_train, cv=kf, scoring='r2')\n",
        "\n",
        "print(f\"Cross-validated Mean Squared Error (MSE) scores: {cv_mse_scores}\")\n",
        "print(f\"Mean Cross-validated MSE: {cv_mse_scores.mean():.4f}\")\n",
        "print(f\"\\nCross-validated R-squared (R2) scores: {cv_r2_scores}\")\n",
        "print(f\"Mean Cross-validated R2: {cv_r2_scores.mean():.4f}\")"
      ],
      "metadata": {
        "id": "Dy61ujd6fxKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 2"
      ],
      "metadata": {
        "id": "dJ2tPlVmpsJ0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "JWYfwnehpsJ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 2 Implementation: Random Forest Regressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# Instantiate the Random Forest Regressor model\n",
        "# You can adjust hyperparameters like n_estimators, max_depth, etc.\n",
        "model_rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "\n",
        "# Fit the Algorithm\n",
        "model_rf.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the model\n",
        "y_pred_rf = model_rf.predict(X_test)\n",
        "\n",
        "# Visualizing evaluation Metric Score chart (using print for now)\n",
        "# Calculate Mean Squared Error\n",
        "mse_rf = mean_squared_error(y_test, y_pred_rf)\n",
        "\n",
        "# Calculate R-squared score\n",
        "r2_rf = r2_score(y_test, y_pred_rf)\n",
        "\n",
        "# Print the evaluation metrics\n",
        "print(f\"Random Forest Regressor Performance on Test Set:\")\n",
        "print(f\"Mean Squared Error (MSE): {mse_rf:.4f}\")\n",
        "print(f\"R-squared (R2) Score: {r2_rf:.4f}\")"
      ],
      "metadata": {
        "id": "yEl-hgQWpsJ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "-jK_YjpMpsJ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cross-Validation for Random Forest Regressor\n",
        "from sklearn.model_selection import KFold, cross_val_score\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "# Re-instantiate the Random Forest Regressor model for CV\n",
        "model_rf_cv = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "\n",
        "# Define the number of splits for K-Fold cross-validation\n",
        "n_splits = 5  # You can adjust this number\n",
        "\n",
        "# Instantiate KFold\n",
        "kf_rf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
        "\n",
        "# Perform cross-validation using MSE and R-squared as scoring metrics\n",
        "cv_mse_scores_rf = -cross_val_score(model_rf_cv, X_train, y_train, cv=kf_rf, scoring='neg_mean_squared_error')\n",
        "cv_r2_scores_rf = cross_val_score(model_rf_cv, X_train, y_train, cv=kf_rf, scoring='r2')\n",
        "\n",
        "print(f\"\\nCross-validated Mean Squared Error (MSE) scores (Random Forest): {cv_mse_scores_rf}\")\n",
        "print(f\"Mean Cross-validated MSE (Random Forest): {cv_mse_scores_rf.mean():.4f}\")\n",
        "print(f\"\\nCross-validated R-squared (R2) scores (Random Forest): {cv_r2_scores_rf}\")\n",
        "print(f\"Mean Cross-validated R2 (Random Forest): {cv_r2_scores_rf.mean():.4f}\")"
      ],
      "metadata": {
        "id": "Dn0EOfS6psJ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Which Evaluation metrics did you consider for a positive business impact and why?"
      ],
      "metadata": {
        "id": "h_CCil-SKHpo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For this regression task (predicting `productivity_score`), the key evaluation metrics considered for positive business impact are:\n",
        "\n",
        "1.  **Mean Squared Error (MSE):** This measures the average squared difference between the actual and predicted `productivity_score`. A lower MSE indicates that the model's predictions are closer to the actual values on average. From a business perspective, a lower MSE means the AI is making more accurate predictions about a user's potential productivity, which is crucial for providing relevant and effective personalized recommendations. More accurate predictions can lead to better user outcomes and higher user satisfaction.\n",
        "2.  **R-squared (R2) Score:** This metric represents the proportion of the variance in the `productivity_score` that is predictable from the features. An R-squared value closer to 1 indicates that the model explains a larger portion of the variability in the target variable. From a business perspective, a higher R-squared means the model is better at capturing the factors that influence productivity. This allows the AI to understand the drivers of productivity more effectively and tailor recommendations that are more likely to have a positive impact on a user's productivity.\n",
        "\n",
        "Both metrics contribute to positive business impact by indicating the model's ability to accurately predict and understand the factors influencing user productivity, which is fundamental for delivering valuable personalized wellness recommendations. There aren't direct insights from these metrics that *lead* to negative growth, but poor scores (high MSE, low R-squared) would indicate a model that is not effectively predicting productivity, which could lead to ineffective or irrelevant recommendations, potentially decreasing user engagement and satisfaction."
      ],
      "metadata": {
        "id": "jHVz9hHDKFms"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Which ML model did you choose from the above created models as your final prediction model and why?"
      ],
      "metadata": {
        "id": "cBFFvTBNJzUa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Based on the evaluation metrics from both the test set and cross-validation, the **Linear Regression model** is the better performing model for this specific task and dataset.\n",
        "\n",
        "*   It achieved a lower Mean Squared Error (MSE) on both the test set (0.9830 vs 1.0878) and in cross-validation (mean CV MSE 1.1447 vs 1.2301).\n",
        "*   It achieved a higher R-squared (R2) score on both the test set (0.1492 vs 0.0585) and in cross-validation (mean CV R2 0.1235 vs 0.0563).\n",
        "\n",
        "While the R-squared scores for both models are relatively low (indicating that the features in this synthetic dataset only explain a small portion of the variance in productivity), Linear Regression captured more of the variance and had lower prediction errors compared to the default Random Forest model. For this dataset, the simpler linear model seems to be more effective."
      ],
      "metadata": {
        "id": "6ksF5Q1LKTVm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***Phase 2: Imapct and reflection***"
      ],
      "metadata": {
        "id": "o7-3XO_gFpbP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Q4. Real-world Impact & Consideration"
      ],
      "metadata": {
        "id": "6SBoP3wLFvev"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Actionable Insights and Potential Value:**\n",
        "\n",
        "1.  **Personalized Recommendations:** The core value is the ability to provide tailored recommendations based on an individual user's data. For example:\n",
        "    -   **Sleep Improvement:** If the AI detects a pattern of low mood or productivity following nights with less than 7 hours of sleep, it could recommend specific sleep hygiene practices or suggest adjusting bedtime.\n",
        "    -   **Stress Management:** If high stress levels correlate with decreased productivity or mood for a user, the AI could suggest stress-reducing activities like mindfulness exercises, breaks, or specific physical activities.\n",
        "    -   **Activity Encouragement:** If there's a detected positive link between daily steps and mood/productivity, the AI could set personalized step goals and provide encouragement.\n",
        "    -   **Dietary Suggestions:** Based on the dietary category and its correlation with wellness metrics, the AI could suggest dietary adjustments or provide information about the impact of nutrition.\n",
        "    -   **Proactive Support:** The AI could identify potential negative trends early (e.g., consistently rising stress, declining sleep) and offer support or suggest interventions before they significantly impact well-being.\n",
        "2.  **Trend Identification:** Users can track their wellness over time and visualize trends, helping them understand the long-term impact of their habits.\n",
        "3.  **Behavior Change Facilitation:** By providing data-driven insights and personalized goals, the AI can motivate users to adopt healthier habits.\n",
        "4.  **Early Warning System:** The AI could potentially flag patterns that might indicate a need for professional medical or psychological advice.\n",
        "\n",
        "**Primary Risks, Ethical Considerations, and Limitations:**\n",
        "\n",
        "1.  **Data Privacy and Security:** This is paramount. Collecting sensitive personal health and behavioral data requires robust security measures to prevent breaches. Users need to trust that their data is protected and used ethically.\n",
        "2.  **Recommendation Bias:**\n",
        "    -   **Algorithmic Bias:** If the data used to train the AI is biased (e.g., primarily reflects the habits of a certain demographic), the recommendations might not be effective or appropriate for all users.\n",
        "    -   **Reinforcing Negative Behaviors:** The AI needs to be carefully designed to avoid inadvertently reinforcing unhealthy patterns or behaviors.\n",
        "3.  **Over-reliance and Misinterpretation:** Users might become overly reliant on the AI's recommendations and ignore their own intuition or professional medical advice. Misinterpreting the AI's suggestions could also be harmful.\n",
        "4.  **Accuracy and Generalizability:**\n",
        "    -   **Synthetic Data Limitations:** As seen with our synthetic data, even well-designed synthetic data is a simplification of complex real-world interactions. Models trained solely on synthetic data might not generalize well to diverse real-world users.\n",
        "    -   **Individual Variability:** Wellness is highly personal. What works for one person might not work for another, even with similar data patterns. The AI needs to account for individual differences and allow for flexibility.\n",
        "5.  **Defining \"Wellness\" and Metrics:** Quantifying subjective concepts like \"mood\" and \"productivity\" is challenging. The metrics used in the data might not fully capture the nuances of a user's well-being.\n",
        "6.  **Lack of Human Empathy and Context:** An AI cannot replace the empathy, understanding, and nuanced advice that human wellness coaches, therapists, or doctors can provide. It lacks the ability to understand the full context of a user's life.\n",
        "7.  **Ethical Use of Insights:** There's a risk that the insights gained from user data could be used in ways that are not in the user's best interest (e.g., for marketing unhealthy products, or by employers/insurance companies).\n",
        "\n",
        "**Significant Limitations if Deployed (especially based on simple models):**\n",
        "\n",
        "-   Models like Linear Regression, while interpretable, might miss complex, non-linear interactions crucial for personalized recommendations in real-world scenarios.\n",
        "-   Predicting highly variable outcomes like mood and productivity with limited features (as in our synthetic data) will likely result in models with low predictive power (as indicated by the relatively low R-squared scores), leading to less impactful recommendations.\n",
        "-   The AI's ability to provide truly *personalized* recommendations requires longitudinal data for individual users to understand their unique patterns, not just cross-sectional data from a diverse group."
      ],
      "metadata": {
        "id": "uN28TsV5GRKn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Q5: Challenges & Growth"
      ],
      "metadata": {
        "id": "yRFJ9GHSGgdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "One of the challenges i faced was in creating a synthetic data for the wellnes AI, SInce i have always worked upon `real-world` data from Kaggle, Huggingface, etc.\n",
        "\n",
        "I worked upon this issue and created relevant features for the purpose of a wellness AI program and filled the data synthetically by learning from resources such as Youtube, Numpy and Pandas Documentation, Gemini, ChatGPT."
      ],
      "metadata": {
        "id": "7eDBEdAuGijG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##***Future Work***"
      ],
      "metadata": {
        "id": "EyNgTHvd2WFk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Save the best performing ml model in a pickle file or joblib file format for deployment process.\n"
      ],
      "metadata": {
        "id": "KH5McJBi2d8v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the File\n",
        "import joblib\n",
        "\n",
        "# Save the model to a file\n",
        "joblib.dump(model_rf, 'wellness_model.pkl')"
      ],
      "metadata": {
        "id": "bQIANRl32f4J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Again Load the saved model file and try to predict unseen data for a sanity check.\n"
      ],
      "metadata": {
        "id": "iW_Lq9qf2h6X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the File and predict unseen data.\n",
        "# Load the trained model\n",
        "model_path = 'wellness_model.pkl'\n",
        "try:\n",
        "    loaded_model = joblib.load(model_path)\n",
        "    print(f\"Model loaded successfully from '{model_path}'.\")\n",
        "except FileNotFoundError:\n",
        "    raise FileNotFoundError(f\"Could not find the model file at '{model_path}'.\")\n",
        "\n",
        "# Ensure X_test exists and is a valid DataFrame\n",
        "if 'X_test' not in globals():\n",
        "    raise ValueError(\"X_test is not defined. Please make sure the test data is loaded.\")\n",
        "\n",
        "# Select the first row of unseen data\n",
        "unseen_data = X_test.iloc[[0]]  # [[0]] ensures it remains a DataFrame\n",
        "\n",
        "# Make prediction\n",
        "try:\n",
        "    prediction = loaded_model.predict(unseen_data)\n",
        "    print(\"Prediction for the first unseen test sample:\", prediction[0])\n",
        "except Exception as e:\n",
        "    print(\"An error occurred during prediction:\", str(e))\n"
      ],
      "metadata": {
        "id": "oEXk9ydD2nVC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Congrats! Your model is successfully created and ready for deployment on a live server for a real user interaction !!!***"
      ],
      "metadata": {
        "id": "-Kee-DAl2viO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusion**"
      ],
      "metadata": {
        "id": "gCX9965dhzqZ"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "73a2c55a"
      },
      "source": [
        "This project demonstrated a proof-of-concept for a **Personalized Wellness AI** using synthetic data. We conducted **EDA** to examine distributions and correlations among wellness metrics such as sleep, steps, stress, mood, and productivity. Notable findings included positive links between sleep and mood, and negative associations between stress and productivity.\n",
        "\n",
        "**Hypothesis testing** confirmed several of these trends statistically, including the positive impact of sleep and steps on mood and productivity, and the negative impact of stress.\n",
        "\n",
        "In the **modeling phase**, we predicted `productivity_score` using Linear Regression and Random Forest. After preprocessing (e.g., one-hot encoding and date feature engineering), **Linear Regression performed slightly better**, though both models showed limited explanatory power, likely due to the simplicity of the synthetic data.\n",
        "\n",
        "A key **challenge** was generating realistic data that mirrors complex human behavior. Despite efforts, synthetic data lacks the nuance of real-world wellness patterns.\n",
        "\n",
        "### Future directions:\n",
        "\n",
        "-   Use **real-world datasets** for better generalization.\n",
        "\n",
        "-   Explore **advanced models** and **hyperparameter tuning**.\n",
        "\n",
        "-   Apply **time-series analysis** for temporal insights.\n",
        "\n",
        "-   Move toward **individualized modeling**.\n",
        "\n",
        "-   Develop a **deployment strategy** with ethical safeguards."
      ]
    }
  ]
}